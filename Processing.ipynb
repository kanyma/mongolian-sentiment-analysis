{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# amazon data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/home/ubuntu/Downloads/amazonreviews/train.ft.txt\", sep='\\t',header=None)\n",
    "test_df = pd.read_csv(\"/home/ubuntu/Downloads/amazonreviews/test.ft.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = train_df[0]\n",
    "test_s = test_df['test data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = [test_s[y] for y in range(0, 3000)]\n",
    "train = [s[x] for x in range(0, 10000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__label__2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(s[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [x[10:] for x in train]\n",
    "train_y = [word_tokenize(y)[0] for y in train]\n",
    "\n",
    "test_x = [h[10:] for h in test]\n",
    "test_y = [word_tokenize(g)[0] for g in test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_xd = pd.DataFrame(train_x, columns=['text'])\n",
    "# test_xd = pd.DataFrame(test_x, columns=['text'])\n",
    "\n",
    "# test_ys = pd.DataFrame(test_y, columns=['labels'])\n",
    "# train_ys = pd.DataFrame(train_y, columns=['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dev_xs = train_xd['text'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "# test_xs = test_xd['text'].apply( lambda x: word_tokenize(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_dev_xss=pd.DataFrame(train_dev_xs,columns=['text'])\n",
    "# test_xss=pd.DataFrame(test_xs,columns=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"reviews_shuffled.txt\", sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=[x[-3:] for x in train_df[0]]\n",
    "data = [x[:-3] for x in train_df[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['| 1', '| 1', '| 1', '| 0', '| 1', '| 0', '| 1', '| 0', '| 1', '| 0']\n",
      "['a small movie with a big impact ', 'deliberately and skillfully uses ambiguity to suggest possibilities which imbue the theme with added depth and resonance ', 'poetry in motion captured on film while it can be a bit repetitive overall it s an entertaining and informative documentary ', 'basically a static series of semi improvised and semi coherent raps between the stars ', 'will assuredly rank as one of the cleverest most deceptively amusing comedies of the year ', 'did no one on the set have a sense of humor or did they not have the nerve to speak up ', 'young hanks and fisk who vaguely resemble their celebrity parents bring fresh good looks and an ease in front of the camera to the work ', 'too slick and manufactured to claim street credibility ', 'passable entertainment but it s the kind of motion picture that won t make much of a splash when it s released and will not be remembered long afterwards ', 'the messages of compassion and mercy are clearly squarely and specifically expounded via computer animated old testament tale of jonah and the whale determined to be fun and bouncy with energetic musicals the humor didn t quite engage this adult ']\n"
     ]
    }
   ],
   "source": [
    "print(label[0:10])\n",
    "print(data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [data[x] for x in range(0, 9000)]\n",
    "train_y = [label[i] for i in range(0, 9000)]\n",
    "\n",
    "\n",
    "test_x = [data[j] for j in range(9002,10662)]\n",
    "test_y = [label[o] for o in range(9002,10662)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a small movie with a big impact ', 'deliberately and skillfully uses ambiguity to suggest possibilities which imbue the theme with added depth and resonance ', 'poetry in motion captured on film while it can be a bit repetitive overall it s an entertaining and informative documentary ', 'basically a static series of semi improvised and semi coherent raps between the stars ', 'will assuredly rank as one of the cleverest most deceptively amusing comedies of the year ', 'did no one on the set have a sense of humor or did they not have the nerve to speak up ', 'young hanks and fisk who vaguely resemble their celebrity parents bring fresh good looks and an ease in front of the camera to the work ', 'too slick and manufactured to claim street credibility ', 'passable entertainment but it s the kind of motion picture that won t make much of a splash when it s released and will not be remembered long afterwards ', 'the messages of compassion and mercy are clearly squarely and specifically expounded via computer animated old testament tale of jonah and the whale determined to be fun and bouncy with energetic musicals the humor didn t quite engage this adult ']\n",
      "['| 1', '| 1', '| 1', '| 0', '| 1', '| 0', '| 1', '| 0', '| 1', '| 0']\n",
      "['this picture is mostly a lump of run of the mill profanity sprinkled with a few remarks so geared toward engendering audience sympathy that you might think he was running for office or trying to win over a probation officer ', 'adaptation is intricately constructed and in a strange way nails all of orlean s themes without being a true adaptation of her book ', 'terminally bland painfully slow and needlessly confusing the movie shot on digital videotape rather than film is frequently indecipherable ', ' tries to parody a genre that s already a joke in the united states the movie is the equivalent of french hip hop which also seems to play on a 10 year delay ', 'the attempt is courageous even if the result is wildly uneven ', 'the film didn t move me one way or the other but it was an honest effort and if you want to see a flick about telemarketers this one will due ', 'a workshop mentality prevails ', 'a cellophane pop remake of the punk classic ladies and gentlemen the fabulous stains crossroads is never much worse than bland or better than inconsequential ', 'with minimal imagination you could restage the whole thing in your bathtub ', ' butterfingered is the word for the big fisted direction of jez butterworth who manages to blast even the smallest sensitivities from the romance with his clamorous approach ']\n",
      "['| 0', '| 1', '| 0', '| 0', '| 0', '| 0', '| 0', '| 0', '| 0', '| 0']\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0:10])\n",
    "print(train_y[0:10])\n",
    "\n",
    "print(test_x[0:10])\n",
    "print(test_y[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goverment 1111.mn dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/ubuntu/Downloads/mongolian-government-agency-1111mn-dataset/1111_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency</th>\n",
       "      <th>content</th>\n",
       "      <th>created_at</th>\n",
       "      <th>source_text</th>\n",
       "      <th>status_text</th>\n",
       "      <th>type_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Нийслэлийн Засаг даргын Тамгын газар</td>\n",
       "      <td>Дулааны тухай</td>\n",
       "      <td>2012-10-13T16:33:29.484371Z</td>\n",
       "      <td>Дуудлага</td>\n",
       "      <td>Хаагдсан</td>\n",
       "      <td>Гомдол</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ерөнхий сайд</td>\n",
       "      <td>Ерөнхий сайдтай уулзах. Жолоочийн эрх ашиг алд...</td>\n",
       "      <td>2012-10-13T16:33:29.492197Z</td>\n",
       "      <td>Биечлэн</td>\n",
       "      <td>Хаагдсан</td>\n",
       "      <td>Санал хүсэлт</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Хүнс, хөдөө аж ахуй, хөнгөн үйлдвэрийн яам</td>\n",
       "      <td>Нефтийн үйлдвэр байгуулах тухай.</td>\n",
       "      <td>2012-10-13T16:33:29.495729Z</td>\n",
       "      <td>Дуудлага</td>\n",
       "      <td>Хаагдсан</td>\n",
       "      <td>Санал хүсэлт</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Цагдаагийн ерөнхий газар</td>\n",
       "      <td>Жолооны үнэмлэх яагаад хэвлэгдэхгүй байна ?</td>\n",
       "      <td>2012-10-13T16:33:29.499487Z</td>\n",
       "      <td>Дуудлага</td>\n",
       "      <td>Хаагдсан</td>\n",
       "      <td>Санал хүсэлт</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Эрүүл мэндийн яам</td>\n",
       "      <td>БГД Гэмтэл-н эмнэлгийн гадуурх хашааг нураах т...</td>\n",
       "      <td>2012-10-13T16:33:29.503063Z</td>\n",
       "      <td>Дуудлага</td>\n",
       "      <td>Хаагдсан</td>\n",
       "      <td>Гомдол</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       agency  \\\n",
       "0        Нийслэлийн Засаг даргын Тамгын газар   \n",
       "1                                Ерөнхий сайд   \n",
       "2  Хүнс, хөдөө аж ахуй, хөнгөн үйлдвэрийн яам   \n",
       "3                    Цагдаагийн ерөнхий газар   \n",
       "4                           Эрүүл мэндийн яам   \n",
       "\n",
       "                                             content  \\\n",
       "0                                      Дулааны тухай   \n",
       "1  Ерөнхий сайдтай уулзах. Жолоочийн эрх ашиг алд...   \n",
       "2                   Нефтийн үйлдвэр байгуулах тухай.   \n",
       "3        Жолооны үнэмлэх яагаад хэвлэгдэхгүй байна ?   \n",
       "4  БГД Гэмтэл-н эмнэлгийн гадуурх хашааг нураах т...   \n",
       "\n",
       "                    created_at source_text status_text     type_text  \n",
       "0  2012-10-13T16:33:29.484371Z    Дуудлага    Хаагдсан        Гомдол  \n",
       "1  2012-10-13T16:33:29.492197Z     Биечлэн    Хаагдсан  Санал хүсэлт  \n",
       "2  2012-10-13T16:33:29.495729Z    Дуудлага    Хаагдсан  Санал хүсэлт  \n",
       "3  2012-10-13T16:33:29.499487Z    Дуудлага    Хаагдсан  Санал хүсэлт  \n",
       "4  2012-10-13T16:33:29.503063Z    Дуудлага    Хаагдсан        Гомдол  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = []\n",
    "trainlabel = []\n",
    "for i in range(0,len(df)):\n",
    "    if (df['type_text'][i]=='Гомдол' or df['type_text'][i]=='Талархал'):\n",
    "             traindata.append(df['content'][i])\n",
    "             trainlabel.append(df['type_text'][i])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_xc = [traindata[x] for x in range(0, 9000)]\n",
    "train_yc = [trainlabel[i] for i in range(0, 9000)]\n",
    "\n",
    "\n",
    "test_xc = [traindata[j] for j in range(9002,11662)]\n",
    "test_yc = [trainlabel[o] for o in range(9002,11662)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Дулааны тухай', 'БГД Гэмтэл-н эмнэлгийн гадуурх хашааг нураах тухай', 'Ахмад-н тухай хууль.Хөгжилийн бэрхшээлтэй иргэдэд. /Портес/ эмчилгээний хөнгөлөлт үйлчилгээний тухай.', 'Байрны түрээсийн үнэ хэтэрхий үнэтэй байна. Төрөөс үүнд хяналт тавих.', '805 хойно зам тавиад зогссон. хашааны өмнө 4хуруу өтгөн шороо байна. маш их бужигнаж байна. эрүүл мэндээрээ хохирч байна. БЗД-р 3-р хороо утаагүй зуух өгөхгүй байна.', 'БЗД 5-р хороо 204-р байр. Сөх-дхүйтэн ус байнга хаагаад байнаа, кино үйлдвэр 204-байр.', 'Эко-н барилга аягуу их баригдаж байна. Барилгаа их ойрхон барьcнаас болж машины зогсоол хүрэлцээ муу байна. энэ асуудлаас болж түгжрэл гарж ард иргэдииг их бухимдуулж байна. Бүх машиныг ниитэд нь утасны дугаартай болгох тухай.', 'Баян-Өлгий аймагт гоо сайхны салон ажиллуулдаг. Удаа дараа цонх хагалсан, машин шатаасан . Эд материалын болон сэтгэл санааны хохирол учирсан. Эзэн нь олдохгүй хэрэг шийдэгдэхгүй байна.Тэмүүжин сайд хуулиа хэрэгжүүлэх тал дээр анхаарлаа хандуулаач ээ', 'кино үйлдвэрийн 204р байранд халуун хүйтэн ус одоог хүртэл байхгүй бн СӨХ дарга ажлаа хийхгүй бн', 'Дархан хотоос: Хаянхярваа гишүүн Баянхонгорын зам засварыг Дарханд авч ирээд нутгийнхаа хүмүүсийг ажиллуулаад байна. Нутагархаг үзлийг халмаар байна. Намын энэ системийг халмаар байна.']\n",
      "['Гомдол', 'Гомдол', 'Гомдол', 'Гомдол', 'Гомдол', 'Гомдол', 'Гомдол', 'Гомдол', 'Гомдол', 'Гомдол']\n",
      "['БГД-ийн 2-р хороо 2-р хороолол эко 57-р байр. Манай байранд халуун ус тасарч сар болж байна. 06.30-нд халуун ус ирнэ гэсэн боловч одоо болтол ирэхгүй байна. Энэ талаар ОСК-оос асуухад бид нар мэдэхгүй дулаанаас асуу гэж байна. Дулааны газраас одоо өглөө гэж өдий хүрч байна. Арга хэмжээ авч өгнө үү.', 'БГДүүргийн 4-р хороолын 8-р байр 2015 оны 06-р сарын 13-нд халуун ус тасраад одоо болтол ирэхгүй байгаад гомдолтой байна. Иймд энэ асуудлыг холбогдох газар нь уламжилж яаралтай шийдвэрлэж өгнө үү. Холбоо барих утас: 99241638', 'БЗДүүргийн 1-р хороо 8-1р байранд 22 цагаас хойш Дэнж хотхон контор нь хэрэглээний халуун хүйтэн усыг хааж байгаад гомдолтой байна. Иймд энэ асуудлыг холбогдох газар нь уламжилж арга хэмжээ авч өгнө үү. Холбоо барих утас 99115839', 'БГДүүргийн 8-р хорооны 25-2 байрны 2015 оны 06-р сарын 13-нь тасраад одоо болтол халуун ус ирэхгүй байгаад гомдолтой байна. Ингэж тасалж байгаа нь ямар учиртай юм бэ? Энэ талаар тодорхой мэдээлэл өгнө үү.', 'БГДүүргийн 4-р хорооллын 41-р байр дээврээсээ дусаал гоожоод 8 жил болж байна. Иймд энэ асуудлыг холбогдох газар нь яаралтай уламжилж арга хэмжээ авч өгнө үү', 'БЗДүүргийн замын цагдаа Амарсанаад гомдолтой байна.72 цаг орсон машин байна гэж зогсоогоод явуулахүй 10,0 төгрөгний торгууль ноогдуулж байна.Машиныхаа дугаарыг авах гээд явж байна гээд учир байдлаа тайлбарлаад хэлж байхад хүлээж авахгүй байна.Энэ асуудалд гомдолтой байна.', 'Эрүүл мэндийн түргэн тусламжийн 103-ийн эмч Одгэрэл 0562 гэсэн дугаартай жолоочид талархаж байна.', 'БЗД Сансарын 15-р хороолол 4-р хорооны 42-р байрны хойд талд авто угаалгаас бохир нь халиад орчин бохирдуулж байна. Дүүргээс ямар ямар ч арга авахгүй байна. Арга хэмжээ авч өгнө үү.', 'Наадмын тасалбар маш хүнд сурталтай зарагдаж байна. 100 хүнд өдөрт 200 билет зарагдлаа гээд дууссан гээд хаагаад явж байна. 2 өдөр очерлож зогссон хүмүүс хохирч байна. Бусад билетүүд нь хаагуур яаж зарагдаад байна вэ. Хонож очерлосон хүмүүст хүртээх хэрэгтэй шүү дээ.', 'ХУД эрүүл мэндийн эмнэлэг сүреэгийн эмч Отгонхүүд талархаж байна. Олон эмийн тасгийн сүреэгийн хяналтанд байдаг юм. Маш сайн эмчилгээ үйлчилгээтэй, иргэнтэй зөв боловсон ёс зүйтэй харьцаж үйлчилгээ үзүүлдэг учир талархаж байна.']\n",
      "['Гомдол', 'Гомдол', 'Гомдол', 'Гомдол', 'Гомдол', 'Гомдол', 'Талархал', 'Гомдол', 'Гомдол', 'Талархал']\n"
     ]
    }
   ],
   "source": [
    "print(train_xc[0:10])\n",
    "print(train_yc[0:10])\n",
    "\n",
    "print(test_xc[0:10])\n",
    "print(test_yc[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "train_xs = vectorizer.fit_transform(train_xc)\n",
    "test_xs = vectorizer.transform(test_xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_iter_no_change=5, presort='deprecated',\n",
       "                           random_state=23, subsample=1.0, tol=0.01,\n",
       "                           validation_fraction=0.5, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=200,\n",
    "                                   validation_fraction=0.5,\n",
    "                                   n_iter_no_change=5,\n",
    "                                   tol=0.01,\n",
    "                                   random_state=23)\n",
    "\n",
    "### 1/5 of full training data.\n",
    "# model = GradientBoostingClassifier(n_estimators=200,\n",
    "#                                    validation_fraction=len(dev_df)/len(train_df),\n",
    "#                                    n_iter_no_change=5,\n",
    "#                                    tol=0.01,\n",
    "#                                    random_state=23)\n",
    "\n",
    "model.fit(train_xs, train_yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Гомдол       0.96      1.00      0.98      2199\n",
      "    Талархал       0.99      0.80      0.89       461\n",
      "\n",
      "    accuracy                           0.96      2660\n",
      "   macro avg       0.97      0.90      0.93      2660\n",
      "weighted avg       0.97      0.96      0.96      2660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_yc, model.predict(test_xs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2195    4]\n",
      " [  90  371]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_yc, model.predict(test_xs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['90', 'about', 'above', 'act', 'acted', 'acting', 'action', 'actor', 'actors', 'actress', 'actually', 'adaptation', 'add', 'adventure', 'after', 'again', 'against', 'age', 'air', 'all', 'allen', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'america', 'american', 'amusing', 'an', 'and', 'animated', 'animation', 'another', 'any', 'anyone', 'anything', 'appeal', 'approach', 'are', 'around', 'art', 'as', 'at', 'attempt', 'attempts', 'audience', 'audiences', 'away', 'awful', 'back', 'bad', 'barely', 'be', 'beautiful', 'beautifully', 'because', 'become', 'becomes', 'been', 'before', 'begins', 'behind', 'being', 'believe', 'best', 'better', 'between', 'beyond', 'big', 'bit', 'black', 'bland', 'bond', 'book', 'boring', 'both', 'boy', 'boys', 'brilliant', 'bring', 'british', 'budget', 'but', 'by', 'camera', 'can', 'care', 'case', 'cast', 'century', 'certainly', 'character', 'characters', 'charm', 'charming', 'cheap', 'children', 'cinema', 'cinematic', 'city', 'class', 'classic', 'clever', 'clich', 'cliches', 'close', 'co', 'cold', 'come', 'comedies', 'comedy', 'comes', 'comic', 'coming', 'compelling', 'completely', 'complex', 'concept', 'considerable', 'contrived', 'cool', 'could', 'country', 'crafted', 'creative', 'crime', 'culture', 'cut', 'cute', 'dark', 'david', 'day', 'days', 'de', 'dead', 'deal', 'death', 'debut', 'deep', 'deeply', 'delightful', 'delivers', 'despite', 'dialogue', 'did', 'didn', 'different', 'difficult', 'directed', 'direction', 'director', 'disney', 'do', 'documentary', 'does', 'doesn', 'doing', 'don', 'done', 'down', 'drama', 'dramatic', 'dull', 'dumb', 'during', 'each', 'earnest', 'easily', 'easy', 'effective', 'effects', 'effort', 'either', 'elements', 'else', 'emotional', 'emotionally', 'end', 'ending', 'ends', 'energy', 'engaging', 'engrossing', 'enjoy', 'enjoyable', 'enough', 'entertaining', 'entertainment', 'entirely', 'epic', 'episode', 'era', 'es', 'especially', 'even', 'events', 'ever', 'every', 'everyone', 'everything', 'exactly', 'excellent', 'except', 'execution', 'exercise', 'experience', 'eye', 'eyes', 'face', 'fact', 'fails', 'falls', 'familiar', 'family', 'fans', 'fantasy', 'far', 'fascinating', 'feature', 'feel', 'feeling', 'feels', 'few', 'fi', 'filled', 'film', 'filmmaker', 'filmmakers', 'filmmaking', 'films', 'final', 'finally', 'find', 'fine', 'fire', 'first', 'flat', 'flick', 'for', 'form', 'formula', 'four', 'free', 'french', 'fresh', 'from', 'full', 'fun', 'funny', 'gags', 'game', 'generic', 'genre', 'gentle', 'get', 'gets', 'getting', 'girl', 'give', 'given', 'gives', 'go', 'goes', 'going', 'gone', 'good', 'gorgeous', 'got', 'great', 'grief', 'guys', 'had', 'half', 'handed', 'happy', 'hard', 'has', 'have', 'having', 'he', 'head', 'heart', 'heavy', 'her', 'here', 'hero', 'high', 'hilarious', 'him', 'himself', 'his', 'history', 'hit', 'hollywood', 'home', 'honest', 'hope', 'horror', 'hour', 'hours', 'how', 'however', 'human', 'humor', 'idea', 'ideas', 'if', 'images', 'imagination', 'imagine', 'important', 'impossible', 'impressive', 'in', 'inside', 'instead', 'intelligence', 'intelligent', 'interest', 'interesting', 'into', 'intriguing', 'is', 'isn', 'issues', 'it', 'its', 'itself', 'job', 'john', 'jokes', 'journey', 'just', 'keep', 'keeps', 'kid', 'kids', 'kind', 'know', 'knows', 'la', 'lack', 'lacks', 'last', 'latest', 'laugh', 'laughs', 'lead', 'least', 'leave', 'leaves', 'left', 'length', 'less', 'let', 'level', 'life', 'light', 'like', 'likely', 'line', 'little', 'live', 'lives', 'll', 'long', 'look', 'looking', 'looks', 'lost', 'lot', 'loud', 'love', 'lovely', 'low', 'made', 'make', 'makes', 'making', 'man', 'manages', 'many', 'master', 'material', 'matter', 'may', 'maybe', 'me', 'melodrama', 'men', 'mess', 'message', 'michael', 'middle', 'might', 'mind', 'minute', 'minutes', 'miss', 'modern', 'moment', 'moments', 'mood', 'moral', 'more', 'most', 'mostly', 'movie', 'movies', 'moving', 'mr', 'much', 'music', 'must', 'my', 'mystery', 'narrative', 'nature', 'nearly', 'need', 'needs', 'neither', 'never', 'new', 'next', 'night', 'no', 'none', 'nor', 'not', 'nothing', 'novel', 'now', 'numbers', 'obvious', 'occasionally', 'of', 'off', 'offers', 'often', 'old', 'on', 'once', 'one', 'only', 'opera', 'or', 'original', 'oscar', 'other', 'others', 'otherwise', 'our', 'out', 'over', 'overall', 'own', 'pace', 'paced', 'part', 'particularly', 'passion', 'past', 'people', 'perfect', 'perfectly', 'performance', 'performances', 'personal', 'picture', 'piece', 'place', 'plain', 'play', 'plays', 'pleasure', 'plenty', 'plot', 'poignant', 'point', 'political', 'pop', 'portrait', 'possible', 'potential', 'power', 'powerful', 'predictable', 'premise', 'pretentious', 'pretty', 'previous', 'probably', 'problem', 'production', 'project', 'proves', 'provides', 'psychological', 'put', 'puts', 'que', 'question', 'quiet', 'quirky', 'quite', 'rare', 'rarely', 'rather', 're', 'read', 'real', 'reality', 'really', 'reason', 'recent', 'relationship', 'remains', 'remake', 'remarkable', 'remember', 'rest', 'result', 'rich', 'ride', 'right', 'road', 'role', 'romance', 'romantic', 'run', 'sad', 'same', 'satire', 'satisfying', 'saw', 'say', 'scary', 'scene', 'scenes', 'school', 'sci', 'screen', 'screenplay', 'script', 'second', 'see', 'seeing', 'seem', 'seems', 'seen', 'self', 'sense', 'sequel', 'sequences', 'series', 'serious', 'set', 'several', 'sex', 'she', 'short', 'shot', 'should', 'show', 'shows', 'side', 'silly', 'simple', 'simply', 'since', 'sit', 'slow', 'small', 'smart', 'so', 'soap', 'social', 'solid', 'some', 'someone', 'something', 'sometimes', 'sort', 'soul', 'sound', 'special', 'spirit', 'spy', 'stand', 'star', 'stars', 'starts', 'still', 'stories', 'story', 'storytelling', 'straight', 'strange', 'strong', 'study', 'stuff', 'stunning', 'style', 'subject', 'substance', 'such', 'suffers', 'summer', 'sure', 'surprise', 'surprises', 'surprising', 'surprisingly', 'suspense', 'sweet', 'take', 'takes', 'tale', 'talent', 'taste', 'tedious', 'teen', 'tell', 'terrific', 'than', 'thanks', 'that', 'the', 'theater', 'their', 'them', 'themselves', 'then', 'there', 'these', 'they', 'thin', 'thing', 'things', 'think', 'this', 'thoroughly', 'those', 'though', 'thought', 'thoughtful', 'three', 'thriller', 'through', 'time', 'times', 'tired', 'title', 'to', 'together', 'told', 'tone', 'too', 'top', 'touching', 'tries', 'true', 'truly', 'truth', 'trying', 'turn', 'turns', 'tv', 'two', 'ugly', 'ultimately', 'under', 'unfortunately', 'unsettling', 'up', 'us', 'use', 'used', 'uses', 'usual', 've', 'version', 'very', 'video', 'view', 'viewer', 'viewers', 'violence', 'vision', 'visual', 'visually', 'want', 'wants', 'war', 'warm', 'was', 'watch', 'watching', 'water', 'way', 'ways', 'we', 'well', 'were', 'what', 'when', 'where', 'whether', 'which', 'while', 'white', 'who', 'whole', 'whose', 'why', 'wild', 'will', 'winning', 'wit', 'with', 'without', 'witty', 'woman', 'women', 'won', 'wonder', 'wonderful', 'work', 'working', 'works', 'world', 'worst', 'worth', 'worthy', 'would', 'writer', 'writing', 'written', 'wrong', 'ya', 'year', 'years', 'yet', 'you', 'young', 'your']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1660"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
